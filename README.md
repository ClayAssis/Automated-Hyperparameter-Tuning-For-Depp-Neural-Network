# Automated-Hyperparameter-Tuning-For-Depp-Neural-Network
 How you can do Hyperparameter Optimization for a NeuralNetwork automatically using Optuna. This is an end-to-end code in which I select a problem and design a neural network in PyTorch and then I find the optimal number of layers, drop out, learning rate, and other parameters using Optuna.
 
 This code is base in aproach by Abhishek Thakur. 
 
 The dataset used was "Mechanisms of Action (MoA) Prediction". 
 
 Link to download the dataset-> https://www.kaggle.com/c/lish-moa

  https://www.youtube.com/watch?v=4MK_OJJ82YI


<p align="center"><img src="img\ScreenShot.png" align="center" ALT="HTML" width="alt%"/></p>
